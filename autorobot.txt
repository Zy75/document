修正しました。2017/7/15

ーーーーーーーーーーーー自律走行ロボット企画書ーーーーーーーーーーーーーーーー

１．目的

遠隔地の状態をチェックして、さらには操作するロボットを開発したい。
例えば、出先から家の中にアクセスする。

また労働を肩代わりして、自律的に作業をこなすロボットを開発したい。
物を運ぶというテーマは比較的簡単で良いと思っている。
人を案内したり、何かを探索する、などのテーマもある。

これらのロボットに必要になるのが、ナビゲーションだ。
ナビゲーションは、周囲の環境を把握したうえで、自分の位置を知り、行きたい所に行くのに大事だ。

今開発の視野に入れているのが、特定の物を運ぶ作業を自動でくりかえすロボットだ。
また出先から家の中の特定の物をチェックして、外に通知するロボットも考えている。

この２つを開発するには、自分の位置を知ることが必要になる。

２．（屋内）測位










例としては、コンロの火を消したかチェックするために、ロボットは決められたコースを走り、
コンロの前に行き、コンロの前で写真を撮り、外からその写真を見れるようにする。

あんかを消したかをチェックするのも同じだ。

同じ本を２冊買わないために、家に本の在庫があるかをチェックする企画もある。

２つめの目的は、物を運ぶロボットを作ることだ。

物を運ぶという繰り返し作業をするロボットを自律制御で自動化する。

他にもlidarとSLAMは、屋内などでGPSが使えない環境で、ロボットを自律制御させるのに重要だ。

３．背景

今回、lidarという周囲をレーザースキャンするセンサーを手に入れた

ロボットに決められた経路を走らせるというテーマは以前もやった内容だが、 
以前やったのは、単眼のカメラによる slam ( 自己位置推定と地図作成の同時実行 )であり、
lidarを使ったほうが性能が出ることを期待している

なぜなら、動かないかぎり単眼のカメラでは奥行き情報が得られないが 
ライダーでは 広い水平角度範囲で奥行き情報を得られる。

まず既存の研究を探した。
youtube の動画を探すと少し出てくる。

lidarの代わりにkinectセンサを使うことができる。
スラムのソフトウェアには ros で標準になっているものを使う。
Google のcartographerというスラムソフトのあるが今のところ使っている人は少ない。

2010年ごろのブログ記事では、ハードウェアに掃除ロボットのルンバを使っている例がある。
自律制御に成功しているようだ。

４．企画
ハードウェアは、Raspberry Pi 3を搭載した 四輪車 でオドメトリが取れるもの。

オドメトリを使うと、車輪の回転センサーなど、センサーからの情報を使って、自分の位置に関する情報の足しにできる。

今回手に入れたrplidar A2を載せる。
lidarは、ある高さで水平面内を回転してスキャンするので、２次元の地図ができる。

決められたコースを走らせると書いた。ライントレースロボットは地面に白線が必要だが、
同じことを白線なしでできるのが、lidarとSLAMだ。

コースは、地図を作成したあとに、複数のつながった線分で指定する。

スラムのソフトウェアには ros 標準の gmapping かhector slamを使う。

５．システム構成

<自律走行車に乗せるもの>
lidar
lidarのドライバー ソフト
Ros ソフト
Raspberry pi 3
オドメトリが取れる車輪
バッテリー

<ノート pc>
スラムのソフトウェア
Ros ソフト
自律走行の統合のための rosプログラム

６．作業工程
まずはハードウェアを作る。
車輪、モーター、車体、lidar、raspberry pi 3を組み立てる

次に raspberry pi 3に os をインストールし lidarのドライバーや ros などシステムを構築する。

ノートPCと車体のRaspberryPi3はwifiで通信する。

ノート pc 側では rosをセットアップし、スラムのソフトウェア をインストールし 
自律走行させるための ros のプログラムを書く

自律走行させるためのコードだが 走らせたいコースからずれていたら 修正するという簡単なコードのはずなので 作業は 大変ではないはず
そのソフトに センサー、モーター、スラムのソフト、を統合する機能も持たせるがpublishとsubscribeするだけなのでシンプルに書ける。
