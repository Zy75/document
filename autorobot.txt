修正しました。2017/7/23

ーーーーーーーーーーーー自律走行ロボット企画書ーーーーーーーーーーーーーーーー

１．はじめに

先進国、特に日本では今後、少子高齢化で労働力が不足することが予測される。
この問題はロボットに仕事をさせれば解決できる。
特に人がやりたがらない仕事をロボットにやらせ、魅力のある仕事を人がすることができる。

a. ロボットを使うメリットを挙げる。（まだ実現していないものも含む。）

< 器用でミスをしない。すばやい動きができる。パワーがある。疲れない。飽きない。危険でもOK。汚くてもOK。
センサがわずかな現象を見逃さない。超小型ロボットを作れる。 >　など

器用でミスをしないので、手術ロボットに使うことが期待できる。

パワーを持たせると、重い物を運べる。建設で使う重機など既に社会で活用されている。

疲れない、飽きない、汚いものOKなので、
冒頭で書いたように人がやりたがらない労働などをロボットにさせることができる。
介護、家事、案内、接客、各種作業などの仕事をさせられる。

危険でも大丈夫なので、警備、災害救助や捜索などができる。

小型化できれば、人体に入り込んで機能するロボットになる。

遠隔地の状態を観測して、さらには操作することができる。
出先から家の中をチェックして操作する。
障がい者のために物を取ってくる。
ドローンでセンサネットワークを作って気象観測などができる。

車椅子を改良したロボットなど乗り物にもなる。

工作物なので五感を望みどおり作ることができる。
例えば、見た目がかわいいペットロボットができる。さらに世話の手間がかからない。

b. 足りないこと

これらのうち多くの用途に必要になるのがナビゲーションだ。
ナビゲーションは、周囲の環境を把握したうえで、自分の位置を知り、行きたい所に行くのに大事だ。

また、障害物を避けたり、階段、段差に対処することも必要だ。
動作を学習させる人工知能も不可欠である。

手に相当するアクチュエータや環境を認識するセンサも高性能のものが必要な場合がある。

c.簡単そうなテーマ

物を運ぶロボットで自律的に動くものは比較的簡単そうなので興味がある。
出先から家の中をチェックして操作できるロボットも簡単な例なら今の技術でもできそうだ。

２．課題

今回はナビゲーションに注目する。
そこで、まず第一歩として、屋内の指定した経路をロボットがたどるという課題を設定する。

３．（屋内）測位

この課題にまず必要になるのが自己位置を知ることである。

屋内測位にはいくつかの方法がある。

GPSは、屋内で使うには誤差が大きい。

Wifi測位は、複数のWi-Fi基地局からの電波強度の違いから演算して自己位置を算出する方式だ。
基地局の位置のデータベースが既に構築されている。

beacon測位は、Bluetoothと同じ形式のビーコン発信器を屋内に設置して、
スマホ側がBLEと呼ばれる通信方式の信号強度判別を元に自己位置を推定する。

歩行者自立航法(PDR)は、現在の大半のスマホが備えている加速度、磁気、角速度などのセンサー機能を活用し、
自分の移動方向と移動量を推定します。

ライントレースロボットといって床に白線を引いてたどらせるロボットがあって、技術的に簡単だが、
今回の課題には良くても応用がきかないので除外する。

この他に今、採用を考えている方法にSLAM（自己位置推定と地図作成を同時実行）がある。
インフラを必要としない。
LIDARというレーザースキャンセンサで周囲の障害物との距離を測定できて、形状の重ねあわせで自分の位置を求める。

４．SLAM＋オドメトリ

GPSもWifi測位もbeacon測位も誤差が大きい。

最近、rplidar A2というレーザースキャンセンサ（ライダー）を手にいれたので、SLAMを使ってみる。
センサが水平面内で回転していて、いろんな角度の障害物との距離を測定するので、止まっていても部屋の形状がわかる。

以前動かした、単眼（普通の）カメラによるSLAMでは、条件の良い動きをすることで初めて奥行きが得られた。

lidarはこの点優れているので、以前よりも良い結果を期待している。

５．オドメトリ

先に書いた、歩行者自立航法(PDR)と似た、オドメトリという方法も使う。

センサで車輪の回転量を測ると、ロボットの移動量がわかるので、自分の位置の情報の足しになる。

精度が悪いと逆にレーザースキャンの足を引っ張ってしまうかもしれない。

５．５　一応他の足りない技術について

ロボットに行動を学習させる人工知能も研究されていて、Deep Q Networkという強化学習の手法で、ゲームを人間以上にプレイできる。
deep reinforcement learning、深層強化学習という。
個人的には、人間がお手本を示して、そこからAIが意味を汲みとって効率的に学習できると良いと思っている。

ハードウェアでは、化学物質や匂いのセンサが改良されると面白いことができると思う。

６．既存の開発例

youtubeの動画を探すと開発例がある。

lidarの代わりにkinectセンサを使うこともできる。

2010年ごろのブログ記事では、ハードウェアに掃除ロボットのルンバを使っている例がある。
自律制御に成功しているようだ。
http://ros-robot.blogspot.jp/2010/05/gmapping-roomba.html

４．企画
ハードウェアは、Raspberry Pi 3を搭載した 四輪車 でオドメトリが取れるもの。

今回手に入れたrplidar A2を載せる。

コースは、地図を作成したあとに、複数のつながった線分で指定する。

スラムのソフトウェアには ros 標準の gmapping かhector slamを使う。

７．システム構成

<自律走行車に乗せるもの>
rplidar A2
lidarのドライバーソフトウェア
Rosソフトウェア
Raspberry pi 3
オドメトリが取れる車輪で、車体が２次元で任意の動きができるためのメカナム（またはオムニ）ホイール４つ
バッテリー

<ノート pc>
スラムのソフトウェア
Ros ソフト
自律走行の統合のための rosプログラム

８．段階

モータの制御の確認。
車体側と母艦側でrosをセットアップし、Wifi通信を確立。
車体を組み立てて、母艦側コントローラで人力操作。
オドメトリ調整。
lidar単体試験。
人力操作でロボットを動かしSLAM動作チェック（地図が作成され自己位置が取れているか）。
指定経路を辿らせる自律制御を完成。
 

９．作業工程
まずはハードウェアを作る。
車輪、モーター、車体、lidar、raspberry pi 3を組み立てる

次に raspberry pi 3に os をインストールし lidarのドライバーや ros などシステムを構築する。

ノートPCと車体のRaspberryPi3はwifiで通信する。

ノート pc 側では rosをセットアップし、スラムのソフトウェア をインストールし 
自律走行させるための ros のプログラムを書く

自律走行させるためのコードだが 走らせたいコースからずれていたら 修正するという簡単なコードのはずなので 作業は 大変ではないはず
そのソフトに センサー、モーター、スラムのソフト、を統合する機能も持たせるがpublishとsubscribeするだけなのでシンプルに書ける。
